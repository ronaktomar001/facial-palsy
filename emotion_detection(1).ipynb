{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uVJMGHFNjaf",
        "outputId": "72ad2f41-4534-4b60-ab5a-97f4fc3f18d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ./kaggle\n",
        "!cp kaggle.json ./kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpZz_BIuOCgQ",
        "outputId": "4191a9d6-8329-43fb-aff1-d3a49a7079b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d msambare/fer2013"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My1IeQc2PI-n",
        "outputId": "afa352a5-946e-4fdb-8157-ef3f05e4e87e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/fer2013.zip, /content/fer2013.zip.zip or /content/fer2013.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip /content/fer2013.zip -d/content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BxMQh4y-RX4o"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xvfKMPySBrrz"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9gA9f3avFaV-"
      },
      "outputs": [],
      "source": [
        "train_data = ImageDataGenerator(rescale=1./255)\n",
        "validation_data = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "rClXirOaFaMD",
        "outputId": "1c73f6a4-fd16-4206-83f7-2717f4880c49"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-2494311761.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_generator = train_data.flow_from_directory(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'/content/train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train'"
          ]
        }
      ],
      "source": [
        "#preprocess\n",
        "train_generator = train_data.flow_from_directory(\n",
        "    '/content/train',\n",
        "    target_size=(48, 48),\n",
        "    batch_size=64,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjkQmyeNFZ_G"
      },
      "outputs": [],
      "source": [
        "validation_generator = validation_data.flow_from_directory(\n",
        "    '/content/test',\n",
        "    target_size=(48,48),\n",
        "    batch_size=64,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def count_files_in_subdirs(directory, sets_name):\n",
        "    counts = {}\n",
        "    for items in os.listdir(directory):\n",
        "         item_path= os.path.join(directory, items)\n",
        "         if os.path.isdir(item_path):\n",
        "            counts[items] = len(os.listdir(item_path))\n",
        "    df = pd.DataFrame(counts, index=[sets_name])\n",
        "    return df\n",
        "train_dir = '/content/train'\n",
        "test_dir = '/content/test'\n",
        "\n",
        "train_count = count_files_in_subdirs(train_dir, 'train')\n",
        "print(train_count)\n",
        "test_count = count_files_in_subdirs(test_dir, 'test')\n",
        "print(test_count)"
      ],
      "metadata": {
        "id": "Fznw79ae0cXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "print(\"Number of training and testing images:\", train_count, test_count)\n",
        "# bar chart:\n",
        "df = pd.DataFrame({'Count': [train_count, test_count]}, index=['Train','Test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WP3afk7h3dGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_count.plot(kind='bar')"
      ],
      "metadata": {
        "id": "5III0rB6Wv-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "#ImageDataGenerator has been moved to keras.utils\n",
        "from keras.utils import image_dataset_from_directory # Use image_dataset_from_directory instead of ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.optimizers import Adam\n",
        "import os # Import the 'os' module for directory operations\n",
        "import matplotlib.pyplot as plt # Import Matplotlib for plotting\n"
      ],
      "metadata": {
        "id": "H9q2XVEovMJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTES3RcVeFkt"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import load_img\n",
        "import os # Import the 'os' module for directory operations\n",
        "import matplotlib.pyplot as plt # Import Matplotlib for plotting\n",
        "\n",
        "expression = 'happy'\n",
        "picture_size = 48\n",
        "folder_path = '/content/'\n",
        "plt.figure(figsize= (12,12))\n",
        "for i in range(1, 10, 1):\n",
        "    plt.subplot(3,3,i)\n",
        "    img_path = folder_path + \"train/\" + expression + \"/\" + os.listdir(folder_path + \"train/\" + expression)[i]\n",
        "    img = load_img(img_path, target_size=(picture_size, picture_size))\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_count.plot(kind='bar')"
      ],
      "metadata": {
        "id": "uvVLIN3TXBhd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gURimWdxerfm"
      },
      "outputs": [],
      "source": [
        "expression = 'disgust'\n",
        "picture_size = 48\n",
        "folder_path = '/content/'\n",
        "plt.figure(figsize= (12,12))\n",
        "for i in range(1, 10, 1):\n",
        "    plt.subplot(3,3,i)\n",
        "    img_path = folder_path + \"train/\" + expression + \"/\" + os.listdir(folder_path + \"train/\" + expression)[i]\n",
        "    img = load_img(img_path, target_size=(picture_size, picture_size))\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expression = 'fear'\n",
        "picture_size = 48\n",
        "folder_path = '/content/'\n",
        "plt.figure(figsize= (12,12))\n",
        "for i in range(1, 10, 1):\n",
        "    plt.subplot(3,3,i)\n",
        "    img_path = folder_path + \"train/\" + expression + \"/\" + os.listdir(folder_path + \"train/\" + expression)[i]\n",
        "    img = load_img(img_path, target_size=(picture_size, picture_size))\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GpJssAK4RvvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expression = 'neutral'\n",
        "picture_size = 48\n",
        "folder_path = '/content/'\n",
        "plt.figure(figsize= (12,12))\n",
        "for i in range(1, 10, 1):\n",
        "    plt.subplot(3,3,i)\n",
        "    img_path = folder_path + \"train/\" + expression + \"/\" + os.listdir(folder_path + \"train/\" + expression)[i]\n",
        "    img = load_img(img_path, target_size=(picture_size, picture_size))\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UZracNUfR3hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoDMZD4r5KE3"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "emotion_model = Sequential()\n",
        "\n",
        "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024, activation='relu'))\n",
        "emotion_model.add(Dropout(0.5))\n",
        "emotion_model.add(Dense(7, activation='softmax'))\n",
        "emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "emotion_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model_info = emotion_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=28709 // 64,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=7178 // 64\n",
        ")"
      ],
      "metadata": {
        "id": "D9GeKMVKvvEq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}