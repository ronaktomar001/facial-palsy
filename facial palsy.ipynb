{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMvuan7MRh7YJJjiXW3/DhA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronaktomar001/facial-palsy/blob/main/facial%20palsy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, GlobalMaxPool2D\n",
        "from tensorflow.keras.layers import TimeDistributed, LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "Yl299Y6xVqhp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ./kaggle\n",
        "!cp kaggle.json ./kaggle/"
      ],
      "metadata": {
        "id": "1-YVE9cPVq7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030ab17b-2ef3-49fa-fb72-1931ba0f45fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d gauravsharma99/ck48-5-emotions"
      ],
      "metadata": {
        "id": "ljZQViM7Vq-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0823d41e-cf3e-4d29-9d15-23c092c61724"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/kaggle(1).json"
      ],
      "metadata": {
        "id": "-5BvyQ4CVrBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fdfd8ff-326a-4808-e8db-c8ba60cecf4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `unzip /content/kaggle(1).json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ck48-5-emotions.zip\n",
        "INPUT_PATH = \"./CK+48/\"\n",
        "\n",
        "for dir_ in os.listdir(INPUT_PATH):\n",
        "    count = 0\n",
        "    for f in os.listdir(INPUT_PATH + dir_ + \"/\"):\n",
        "        count += 1\n",
        "    print(f\"{dir_} has {count} number of images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "collapsed": true,
        "id": "lYjCvscFi1DV",
        "outputId": "f34842b1-88ba-4872-b351-6d69459f24dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open ck48-5-emotions.zip, ck48-5-emotions.zip.zip or ck48-5-emotions.zip.ZIP.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './CK+48/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-3554089147.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mINPUT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./CK+48/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdir_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdir_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './CK+48/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOP_EMOTIONS = [\"happy\", \"surprise\", \"anger\", \"sadness\", \"fear\"]"
      ],
      "metadata": {
        "id": "vkOzWu27i_DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_PATH = \"./CK+48/\"\n",
        "\n",
        "data = defaultdict(str)\n",
        "for dir_ in os.listdir(INPUT_PATH):\n",
        "    if dir_ in TOP_EMOTIONS:\n",
        "        data[dir_] = defaultdict(list)\n",
        "        for f in os.listdir(INPUT_PATH + dir_ + \"/\"):\n",
        "            sub = f.split(\"_\")[0]\n",
        "            data[dir_][sub].append(f)"
      ],
      "metadata": {
        "id": "4H_t79Rmi-_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_list(x):\n",
        "    return int((x.split(\"_\")[2]).split(\".\")[0])\n",
        "\n",
        "def preprocess_dict(x):\n",
        "    res = list(np.argsort(list(map(preprocess_list, x))))\n",
        "    return [x[i] for i in res]\n",
        "\n",
        "def img2array(x,path):\n",
        "    arr = np.empty(shape=(3,48,48))\n",
        "    for i,f in enumerate(x):\n",
        "        img = cv2.imread(path+f, 0)\n",
        "        arr[i] = img\n",
        "    return arr"
      ],
      "metadata": {
        "id": "ppRexmYii-9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for emotion in data:\n",
        "    data[emotion] = dict((k, preprocess_dict(v)) for k, v in data[emotion].items())\n",
        "    data[emotion] = dict((k, img2array(v, path=INPUT_PATH + emotion + \"/\")) for k, v in data[emotion].items())\n",
        "\n",
        "for k,v in data.items():\n",
        "    print(f\"{k} has {len(v)} samples\")"
      ],
      "metadata": {
        "id": "URIQ9KMYi-6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "surprise = np.stack(list(data[\"surprise\"].values()), axis=0)\n",
        "surprise = surprise.reshape(*surprise.shape,1)\n",
        "\n",
        "happy = np.stack(list(data[\"happy\"].values()), axis=0)\n",
        "happy = happy.reshape(*happy.shape,1)\n",
        "\n",
        "anger = np.stack(list(data[\"anger\"].values()), axis=0)\n",
        "anger = anger.reshape(*anger.shape,1)\n",
        "\n",
        "sadness = np.stack(list(data[\"sadness\"].values()), axis=0)\n",
        "sadness = sadness.reshape(*sadness.shape,1)\n",
        "\n",
        "fear = np.stack(list(data[\"fear\"].values()), axis=0)\n",
        "fear = fear.reshape(*fear.shape,1)\n",
        "X = np.concatenate((surprise, happy, anger, sadness, fear))\n",
        "y = np.concatenate((np.array([0]*83), np.array([1]*69), np.array([2]*45), np.array([3]*28), np.array([4]*25)))\n",
        "y = to_categorical(y)\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "8mO1jDG4i-3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_emotion_mapper = {0:\"surprise\", 1:\"happy\", 2:\"anger\", 3:\"sadness\", 4:\"fear\"}\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "  X,\n",
        "  y,\n",
        "  train_size=0.7,\n",
        "  stratify=y,\n",
        "  shuffle=True,\n",
        "  random_state=42\n",
        ")\n",
        "\n",
        "print(X_train.shape, X_valid.shape)"
      ],
      "metadata": {
        "id": "TJsQyjlEi-0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "surprise_idx = np.random.choice(np.where(y_train[:, 0]==1)[0], size=1)\n",
        "happy_idx = np.random.choice(np.where(y_train[:, 1]==1)[0], size=1)\n",
        "anger_idx = np.random.choice(np.where(y_train[:, 2]==1)[0], size=1)\n",
        "sad_idx = np.random.choice(np.where(y_train[:, 3]==1)[0], size=1)\n",
        "fear_idx = np.random.choice(np.where(y_train[:, 4]==1)[0], size=1)\n",
        "\n",
        "fig = pyplot.figure(1, (6,13))\n",
        "\n",
        "i = 0\n",
        "for name, idx in zip(label_emotion_mapper.values(), [surprise_idx, happy_idx, anger_idx, sad_idx, fear_idx]):\n",
        "    for j in range(3):\n",
        "        i += 1\n",
        "        ax = pyplot.subplot(5,3,i)\n",
        "        sample_img = X_train[idx][0,j,:,:,0]\n",
        "        ax.imshow(sample_img, cmap='gray')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_title(name)"
      ],
      "metadata": {
        "id": "JNumsauji-xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data normalization\n",
        "X_train = X_train / 255.\n",
        "X_valid = X_valid / 255."
      ],
      "metadata": {
        "id": "UfdkUjaei-uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dcnn(input_shape, show_arch=True):\n",
        "    net = Sequential(name='DCNN')\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(3,3),\n",
        "            input_shape=input_shape,\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_1'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_1'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_2'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_2'))\n",
        "\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n",
        "    net.add(Dropout(0.45, name='dropout_1'))\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=128,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_3'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_3'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=128,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_4'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_4'))\n",
        "\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n",
        "    net.add(Dropout(0.45, name='dropout_2'))\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=256,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_5'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_5'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=256,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_6'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_6'))\n",
        "\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n",
        "    net.add(Dropout(0.4, name='dropout_3'))\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=512,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_7'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_7'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=512,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_8'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_8'))\n",
        "\n",
        "    net.add(Dropout(0.4, name='dropout_4'))\n",
        "\n",
        "    net.add(GlobalMaxPool2D(name=\"globalmax2d\"))\n",
        "\n",
        "    if show_arch:\n",
        "        net.summary()\n",
        "\n",
        "    return net"
      ],
      "metadata": {
        "id": "IKXk5gJti-rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def memory_model(input_shape, num_class, show_arch=True):\n",
        "    dcnn = build_dcnn(input_shape[1:], show_arch=False)\n",
        "\n",
        "    model = Sequential(name=\"convolutional_Bidrectional_LSTM\")\n",
        "\n",
        "    model.add(\n",
        "        TimeDistributed(\n",
        "            dcnn,\n",
        "            input_shape=input_shape,\n",
        "            name=\"time_distributed\",\n",
        "        )\n",
        "    )\n",
        "\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True, name=\"bidirect_lstm_1\")))\n",
        "    model.add(Dropout(.35, name=\"dropout_1\"))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=False, name=\"bidirect_lstm_2\")))\n",
        "    model.add(Dropout(.45, name=\"dropout_2\"))\n",
        "\n",
        "    model.add(\n",
        "        Dense(\n",
        "            128,\n",
        "            activation='elu',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='dense_1'\n",
        "        )\n",
        "    )\n",
        "    model.add(BatchNormalization(name='batchnorm_1'))\n",
        "    model.add(Dropout(.7, name=\"dropout_3\"))\n",
        "\n",
        "    model.add(\n",
        "        Dense(\n",
        "            num_class,\n",
        "            activation='softmax',\n",
        "            name='out_layer'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    if show_arch:\n",
        "        model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "6XO6sP7ai-oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.8,\n",
        "    patience=7,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    lr_scheduler,\n",
        "]\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "ZN2jjzzvi-ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = (3, 48, 48, 1)\n",
        "optim = optimizers.Nadam(0.001)\n",
        "\n",
        "model = memory_model(INPUT_SHAPE, num_class=5)\n",
        "model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=optim,\n",
        "        metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "SJ52Ig8hmGl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    # Removed use_multiprocessing argument as it's not supported\n",
        ")"
      ],
      "metadata": {
        "id": "Fj7cQsIMmMJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set()\n",
        "fig = pyplot.figure(0, (12, 4))\n",
        "\n",
        "ax = pyplot.subplot(1, 2, 1)\n",
        "sns.lineplot(x=history.epoch, y=history.history['accuracy'], label='train')\n",
        "sns.lineplot(x=history.epoch, y=history.history['val_accuracy'], label='valid')\n",
        "pyplot.title('Accuracy')\n",
        "pyplot.tight_layout()\n",
        "\n",
        "ax = pyplot.subplot(1, 2, 2)\n",
        "sns.lineplot(x=history.epoch, y=history.history['loss'], label='train')\n",
        "sns.lineplot(x=history.epoch, y=history.history['val_loss'], label='valid')\n",
        "pyplot.title('Loss')\n",
        "pyplot.tight_layout()\n",
        "\n",
        "pyplot.savefig('epoch_history.png')\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "1LFpDyNNmMDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "indices = np.random.choice(range(X_valid.shape[0]), size=15, replace=False)\n",
        "\n",
        "fig = pyplot.figure(1, (9,30))\n",
        "\n",
        "i = 0\n",
        "for idx in indices:\n",
        "    true_emotion = label_emotion_mapper[np.argmax(y_valid[idx])]\n",
        "    # Use np.argmax to get predicted class index\n",
        "    pred_emotion = label_emotion_mapper[np.argmax(model.predict(np.expand_dims(X_valid[idx], axis=0)), axis=1)[0]]\n",
        "\n",
        "    for j in range(3):\n",
        "        i += 1\n",
        "        ax = pyplot.subplot(15,3,i)\n",
        "        sample_img = X_valid[idx,j,:,:,0]\n",
        "        ax.imshow(sample_img, cmap='gray')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_title(f\"t:{true_emotion}, p:{pred_emotion}\")"
      ],
      "metadata": {
        "id": "heI6qUREmL82"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}